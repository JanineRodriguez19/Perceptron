{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Aquí, inicializamos los pesos (weights) y el umbral (threshold) con valores aleatorios entre -1 y 1. Esto es importante para evitar que la red neuronal comience con todos los pesos iguales, lo que haría que el aprendizaje sea ineficiente. En este ejemplo, n_inputs es el número de entradas, y weights será un vector de pesos que se aplicarán a cada entrada."
      ],
      "metadata": {
        "id": "-tJntmmdLQD0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wJPy5YK4K1Lj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Función de activación: en este caso utilizaremos la función sigmoide\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Derivada de la función sigmoide para el cálculo del error en retropropagación\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Parámetros iniciales\n",
        "learning_rate = 0.1  # Coeficiente de aprendizaje\n",
        "n_inputs = 3  # Número de entradas (esto puede variar dependiendo del problema)\n",
        "n_epochs = 10000  # Número de iteraciones\n",
        "\n",
        "#paso 1 de la imagen\n",
        "# Inicializar los pesos y el umbral con valores aleatorios pequeños entre -1 y 1\n",
        "weights = np.random.uniform(-1, 1, n_inputs)\n",
        "threshold = np.random.uniform(-1, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este ejemplo, X representa los datos de entrada, y D es el conjunto de salidas deseadas (objetivo) para cada entrada de X. Cada fila de X es un conjunto de valores de entrada, y cada elemento de D es la salida esperada correspondiente. En un caso real, estos datos provendrían del conjunto de datos de entrenamiento."
      ],
      "metadata": {
        "id": "FmsfHDGtNjoj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#paso 2 de la imagen\n",
        "# Datos de entrenamiento (ejemplo)\n",
        "X = np.array([[0, 0, 1], [1, 1, 1], [1, 0, 1], [0, 1, 1]])  # Entradas\n",
        "D = np.array([0, 1, 1, 0])  # Salidas deseadas (objetivo)\n",
        "\n",
        "# Algoritmo de entrenamiento\n",
        "for epoch in range(n_epochs):\n",
        "    total_error = 0\n",
        "\n",
        "    for i in range(len(X)):\n",
        "        # Paso 3: Propagación\n",
        "        x_i = X[i]\n",
        "        y = sigmoid(np.dot(x_i, weights) - threshold)\n",
        "\n",
        "        # Paso 4: Calcular el error\n",
        "        error = D[i] - y\n",
        "        total_error += error**2  # Suma de errores cuadráticos\n",
        "\n",
        "        # Paso 5: Retropropagación (ajuste de pesos y umbral)\n",
        "        weights += learning_rate * error * x_i * sigmoid_derivative(y)\n",
        "        threshold -= learning_rate * error * sigmoid_derivative(y)\n",
        "\n",
        "    # Condición de parada si el error es suficientemente bajo\n",
        "    if total_error < 1e-5:\n",
        "        print(f\"Entrenamiento completado en la época {epoch}\")\n",
        "        break"
      ],
      "metadata": {
        "id": "evcj741bNWYr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La retropropagación es el proceso de ajustar los pesos para minimizar el error. Aquí, usamos la fórmula de ajuste de pesos que se basa en el coeficiente de aprendizaje (learning_rate), el error entre la salida deseada y la obtenida, y la derivada de la función de activación (sigmoid_derivative)."
      ],
      "metadata": {
        "id": "aJUbnsbZMvvD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar los pesos finales y el umbral\n",
        "print(\"Pesos finales:\", weights)\n",
        "print(\"Umbral final:\", threshold)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4wsQkZwLv5-",
        "outputId": "2a31b06d-533c-4f14-f96a-74ea75bd6c36"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pesos finales: [ 7.34373864 -0.12305272 -1.56981332]\n",
            "Umbral final: 1.9820713088609487\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "A-SBz4tLM4uS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prueba del modelo\n",
        "for i in range(len(X)):\n",
        "    y = sigmoid(np.dot(X[i], weights) - threshold)\n",
        "    print(f\"Entrada: {X[i]}, Salida esperada: {D[i]}, Salida predicha: {y}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkXZGczSLrgC",
        "outputId": "bbe94c39-3dc1-45ae-9bd2-7dcc510c6a52"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrada: [0 0 1], Salida esperada: 0, Salida predicha: 0.027871465082909497\n",
            "Entrada: [1 1 1], Salida esperada: 1, Salida predicha: 0.9751273992595727\n",
            "Entrada: [1 0 1], Salida esperada: 1, Salida predicha: 0.9779437041255044\n",
            "Entrada: [0 1 1], Salida esperada: 0, Salida predicha: 0.024724210653534397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aquí, usamos los pesos y el umbral finales para calcular la salida de cada entrada X[i] y compararla con la salida deseada D[i]. Esto muestra cómo el modelo está prediciendo después de completar el entrenamiento."
      ],
      "metadata": {
        "id": "VYve0nqVM0rW"
      }
    }
  ]
}